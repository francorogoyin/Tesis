{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis de Congruencia/Incongruencia Ideológica\n",
    "\n",
    "Este notebook analiza los cambios de opinión (CO) y tiempo (CT) según su **congruencia ideológica**.\n",
    "\n",
    "## Definiciones:\n",
    "\n",
    "### **CONGRUENTES** (ideológicamente consistentes):\n",
    "- Ítems **Progresistas** + movimiento hacia **Izquierda**\n",
    "- Ítems **Conservadores** + movimiento hacia **Derecha**\n",
    "\n",
    "### **INCONGRUENTES** (ideológicamente inconsistentes):\n",
    "- Ítems **Progresistas** + movimiento hacia **Derecha**\n",
    "- Ítems **Conservadores** + movimiento hacia **Izquierda**\n",
    "\n",
    "## Análisis:\n",
    "\n",
    "1. Crear variables de Congruencia/Incongruencia para CO y CT\n",
    "2. Comparar Congruente vs Incongruente (todas las poblaciones)\n",
    "3. Comparar por cada categoría (Categoria_PASO_2023)\n",
    "4. Para Generales y Ballotage\n",
    "5. Tablas Excel con resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy import stats\n",
    "from scipy.stats import wilcoxon\n",
    "from openpyxl import Workbook\n",
    "from openpyxl.styles import Font, PatternFill, Alignment, Border, Side\n",
    "from openpyxl.utils import get_column_letter\n",
    "\n",
    "print(\"✓ Librerías cargadas exitosamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Cargar Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rutas a los archivos Excel\n",
    "Ruta_Base = os.path.join(os.getcwd(), '..', 'Data', 'Bases definitivas')\n",
    "Excel_Generales = os.path.join(Ruta_Base, 'Generales.xlsx')\n",
    "Excel_Ballotage = os.path.join(Ruta_Base, 'Ballotage.xlsx')\n",
    "\n",
    "# Cargar DataFrames desde Excel\n",
    "df_Generales = pd.read_excel(Excel_Generales)\n",
    "df_Ballotage = pd.read_excel(Excel_Ballotage)\n",
    "\n",
    "dfs_Finales = {\n",
    "    'Generales': df_Generales,\n",
    "    'Ballotage': df_Ballotage\n",
    "}\n",
    "\n",
    "print(f\"✓ Datos cargados desde Excel:\")\n",
    "print(f\"  - Generales: {len(df_Generales)} registros\")\n",
    "print(f\"  - Ballotage: {len(df_Ballotage)} registros\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Verificar Variables Necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables necesarias para CO\n",
    "vars_necesarias_co = [\n",
    "    'Cambio_Op_Sum_Pro_Izq',\n",
    "    'Cambio_Op_Sum_Pro_Der',\n",
    "    'Cambio_Op_Sum_Con_Izq',\n",
    "    'Cambio_Op_Sum_Con_Der'\n",
    "]\n",
    "\n",
    "# Variables necesarias para CT\n",
    "vars_necesarias_ct = [\n",
    "    'Cambio_Tiempo_Sum_Pro_Izq',\n",
    "    'Cambio_Tiempo_Sum_Pro_Der',\n",
    "    'Cambio_Tiempo_Sum_Con_Izq',\n",
    "    'Cambio_Tiempo_Sum_Con_Der'\n",
    "]\n",
    "\n",
    "print(\"Verificando variables necesarias:\\n\")\n",
    "\n",
    "for nombre_df, df in dfs_Finales.items():\n",
    "    print(f\"{nombre_df}:\")\n",
    "    \n",
    "    # Verificar CO\n",
    "    faltantes_co = [v for v in vars_necesarias_co if v not in df.columns]\n",
    "    if faltantes_co:\n",
    "        print(f\"  ⚠️  Variables CO faltantes: {faltantes_co}\")\n",
    "    else:\n",
    "        print(f\"  ✓ Todas las variables CO presentes\")\n",
    "    \n",
    "    # Verificar CT\n",
    "    faltantes_ct = [v for v in vars_necesarias_ct if v not in df.columns]\n",
    "    if faltantes_ct:\n",
    "        print(f\"  ⚠️  Variables CT faltantes: {faltantes_ct}\")\n",
    "    else:\n",
    "        print(f\"  ✓ Todas las variables CT presentes\")\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Crear Variables de Congruencia e Incongruencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creando variables de Congruencia e Incongruencia...\\n\")\n",
    "\n",
    "for nombre_df, df in dfs_Finales.items():\n",
    "    print(f\"Procesando {nombre_df}...\")\n",
    "    \n",
    "    # CONGRUENTE CO = Progresistas_Izq + Conservadores_Der\n",
    "    if 'Cambio_Op_Sum_Pro_Izq' in df.columns and 'Cambio_Op_Sum_Con_Der' in df.columns:\n",
    "        df['CO_Congruente'] = df['Cambio_Op_Sum_Pro_Izq'] + df['Cambio_Op_Sum_Con_Der']\n",
    "        print(f\"  ✓ CO_Congruente creada\")\n",
    "    \n",
    "    # INCONGRUENTE CO = Progresistas_Der + Conservadores_Izq\n",
    "    if 'Cambio_Op_Sum_Pro_Der' in df.columns and 'Cambio_Op_Sum_Con_Izq' in df.columns:\n",
    "        df['CO_Incongruente'] = df['Cambio_Op_Sum_Pro_Der'] + df['Cambio_Op_Sum_Con_Izq']\n",
    "        print(f\"  ✓ CO_Incongruente creada\")\n",
    "    \n",
    "    # CONGRUENTE CT = Progresistas_Izq + Conservadores_Der\n",
    "    if 'Cambio_Tiempo_Sum_Pro_Izq' in df.columns and 'Cambio_Tiempo_Sum_Con_Der' in df.columns:\n",
    "        df['CT_Congruente'] = df['Cambio_Tiempo_Sum_Pro_Izq'] + df['Cambio_Tiempo_Sum_Con_Der']\n",
    "        print(f\"  ✓ CT_Congruente creada\")\n",
    "    \n",
    "    # INCONGRUENTE CT = Progresistas_Der + Conservadores_Izq\n",
    "    if 'Cambio_Tiempo_Sum_Pro_Der' in df.columns and 'Cambio_Tiempo_Sum_Con_Izq' in df.columns:\n",
    "        df['CT_Incongruente'] = df['Cambio_Tiempo_Sum_Pro_Der'] + df['Cambio_Tiempo_Sum_Con_Izq']\n",
    "        print(f\"  ✓ CT_Incongruente creada\")\n",
    "    \n",
    "    print()\n",
    "\n",
    "print(\"✅ Variables de Congruencia/Incongruencia creadas exitosamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Estadísticas Descriptivas - Todas las Poblaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"ESTADÍSTICAS DESCRIPTIVAS - TODAS LAS POBLACIONES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "variables_analizar = ['CO_Congruente', 'CO_Incongruente', 'CT_Congruente', 'CT_Incongruente']\n",
    "\n",
    "for nombre_df, df in dfs_Finales.items():\n",
    "    print(f\"\\n📊 {nombre_df}:\")\n",
    "    print(\"\\n\" + \"-\"*70)\n",
    "    \n",
    "    for var in variables_analizar:\n",
    "        if var in df.columns:\n",
    "            datos = df[var].dropna()\n",
    "            \n",
    "            if len(datos) > 0:\n",
    "                print(f\"\\n{var}:\")\n",
    "                print(f\"  n = {len(datos)}\")\n",
    "                print(f\"  Media = {datos.mean():.4f}\")\n",
    "                print(f\"  Mediana = {datos.median():.4f}\")\n",
    "                print(f\"  DE = {datos.std():.4f}\")\n",
    "                print(f\"  Min = {datos.min():.4f}\")\n",
    "                print(f\"  Max = {datos.max():.4f}\")\n",
    "            else:\n",
    "                print(f\"\\n{var}: Sin datos\")\n",
    "        else:\n",
    "            print(f\"\\n{var}: Variable no encontrada\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*70)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test de Wilcoxon: Congruente vs Incongruente - Todas las Poblaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"TEST DE WILCOXON PAREADO: CONGRUENTE vs INCONGRUENTE\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nH₀: No hay diferencia entre Congruente e Incongruente\")\n",
    "print(\"H₁: Hay diferencia entre Congruente e Incongruente\\n\")\n",
    "\n",
    "resultados_wilcoxon_general = []\n",
    "\n",
    "for nombre_df, df in dfs_Finales.items():\n",
    "    print(f\"\\n📊 {nombre_df}:\")\n",
    "    print(\"\\n\" + \"-\"*70)\n",
    "    \n",
    "    # Test para CO\n",
    "    if 'CO_Congruente' in df.columns and 'CO_Incongruente' in df.columns:\n",
    "        # Eliminar NaN en ambas variables\n",
    "        datos_pareados = df[['CO_Congruente', 'CO_Incongruente']].dropna()\n",
    "        \n",
    "        if len(datos_pareados) > 0:\n",
    "            try:\n",
    "                stat, p_valor = wilcoxon(datos_pareados['CO_Congruente'], \n",
    "                                        datos_pareados['CO_Incongruente'])\n",
    "                \n",
    "                # Determinar significancia\n",
    "                if p_valor < 0.001:\n",
    "                    sig = '***'\n",
    "                elif p_valor < 0.01:\n",
    "                    sig = '**'\n",
    "                elif p_valor < 0.05:\n",
    "                    sig = '*'\n",
    "                else:\n",
    "                    sig = 'ns'\n",
    "                \n",
    "                print(f\"\\nCO - Congruente vs Incongruente:\")\n",
    "                print(f\"  n pareados = {len(datos_pareados)}\")\n",
    "                print(f\"  Media Congruente = {datos_pareados['CO_Congruente'].mean():.4f}\")\n",
    "                print(f\"  Media Incongruente = {datos_pareados['CO_Incongruente'].mean():.4f}\")\n",
    "                print(f\"  Estadístico W = {stat:.4f}\")\n",
    "                print(f\"  p-valor = {p_valor:.6f}\")\n",
    "                print(f\"  Significancia: {sig}\")\n",
    "                \n",
    "                if sig != 'ns':\n",
    "                    print(f\"  ✅ DIFERENCIA SIGNIFICATIVA\")\n",
    "                else:\n",
    "                    print(f\"  ❌ No significativa\")\n",
    "                \n",
    "                resultados_wilcoxon_general.append({\n",
    "                    'Dataset': nombre_df,\n",
    "                    'Tipo': 'CO',\n",
    "                    'n': len(datos_pareados),\n",
    "                    'Media_Congruente': datos_pareados['CO_Congruente'].mean(),\n",
    "                    'Media_Incongruente': datos_pareados['CO_Incongruente'].mean(),\n",
    "                    'W': stat,\n",
    "                    'p_valor': p_valor,\n",
    "                    'Sig': sig\n",
    "                })\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"\\nCO - Error: {e}\")\n",
    "        else:\n",
    "            print(f\"\\nCO - Sin datos pareados\")\n",
    "    \n",
    "    # Test para CT\n",
    "    if 'CT_Congruente' in df.columns and 'CT_Incongruente' in df.columns:\n",
    "        # Eliminar NaN en ambas variables\n",
    "        datos_pareados = df[['CT_Congruente', 'CT_Incongruente']].dropna()\n",
    "        \n",
    "        if len(datos_pareados) > 0:\n",
    "            try:\n",
    "                stat, p_valor = wilcoxon(datos_pareados['CT_Congruente'], \n",
    "                                        datos_pareados['CT_Incongruente'])\n",
    "                \n",
    "                # Determinar significancia\n",
    "                if p_valor < 0.001:\n",
    "                    sig = '***'\n",
    "                elif p_valor < 0.01:\n",
    "                    sig = '**'\n",
    "                elif p_valor < 0.05:\n",
    "                    sig = '*'\n",
    "                else:\n",
    "                    sig = 'ns'\n",
    "                \n",
    "                print(f\"\\nCT - Congruente vs Incongruente:\")\n",
    "                print(f\"  n pareados = {len(datos_pareados)}\")\n",
    "                print(f\"  Media Congruente = {datos_pareados['CT_Congruente'].mean():.4f}\")\n",
    "                print(f\"  Media Incongruente = {datos_pareados['CT_Incongruente'].mean():.4f}\")\n",
    "                print(f\"  Estadístico W = {stat:.4f}\")\n",
    "                print(f\"  p-valor = {p_valor:.6f}\")\n",
    "                print(f\"  Significancia: {sig}\")\n",
    "                \n",
    "                if sig != 'ns':\n",
    "                    print(f\"  ✅ DIFERENCIA SIGNIFICATIVA\")\n",
    "                else:\n",
    "                    print(f\"  ❌ No significativa\")\n",
    "                \n",
    "                resultados_wilcoxon_general.append({\n",
    "                    'Dataset': nombre_df,\n",
    "                    'Tipo': 'CT',\n",
    "                    'n': len(datos_pareados),\n",
    "                    'Media_Congruente': datos_pareados['CT_Congruente'].mean(),\n",
    "                    'Media_Incongruente': datos_pareados['CT_Incongruente'].mean(),\n",
    "                    'W': stat,\n",
    "                    'p_valor': p_valor,\n",
    "                    'Sig': sig\n",
    "                })\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"\\nCT - Error: {e}\")\n",
    "        else:\n",
    "            print(f\"\\nCT - Sin datos pareados\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*70)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "\n",
    "# Crear DataFrame con resultados\n",
    "df_resultados_general = pd.DataFrame(resultados_wilcoxon_general)\n",
    "print(\"\\n📋 Resumen de Resultados:\\n\")\n",
    "print(df_resultados_general.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Análisis por Categoría (Categoria_PASO_2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"TEST DE WILCOXON POR CATEGORÍA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "Categorias_Validas = [\n",
    "    'Left_Wing', 'Progressivism', 'Centre',\n",
    "    'Moderate_Right_A', 'Moderate_Right_B', 'Right_Wing_Libertarian'\n",
    "]\n",
    "\n",
    "Etiquetas_Categorias = {\n",
    "    'Left_Wing': 'Left Wing',\n",
    "    'Progressivism': 'Progressivism',\n",
    "    'Centre': 'Centre',\n",
    "    'Moderate_Right_A': 'Moderate Right A',\n",
    "    'Moderate_Right_B': 'Moderate Right B',\n",
    "    'Right_Wing_Libertarian': 'Right Wing Libertarian'\n",
    "}\n",
    "\n",
    "resultados_por_categoria = []\n",
    "\n",
    "for nombre_df, df in dfs_Finales.items():\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"📊 Dataset: {nombre_df}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    for categoria in Categorias_Validas:\n",
    "        print(f\"\\n{Etiquetas_Categorias[categoria]}:\")\n",
    "        print(\"-\"*70)\n",
    "        \n",
    "        # Filtrar por categoría\n",
    "        df_cat = df[df['Categoria_PASO_2023'] == categoria].copy()\n",
    "        \n",
    "        # Test para CO\n",
    "        if 'CO_Congruente' in df_cat.columns and 'CO_Incongruente' in df_cat.columns:\n",
    "            datos_pareados = df_cat[['CO_Congruente', 'CO_Incongruente']].dropna()\n",
    "            \n",
    "            if len(datos_pareados) > 1:\n",
    "                try:\n",
    "                    stat, p_valor = wilcoxon(datos_pareados['CO_Congruente'], \n",
    "                                            datos_pareados['CO_Incongruente'])\n",
    "                    \n",
    "                    if p_valor < 0.001:\n",
    "                        sig = '***'\n",
    "                    elif p_valor < 0.01:\n",
    "                        sig = '**'\n",
    "                    elif p_valor < 0.05:\n",
    "                        sig = '*'\n",
    "                    else:\n",
    "                        sig = 'ns'\n",
    "                    \n",
    "                    print(f\"\\n  CO:\")\n",
    "                    print(f\"    n = {len(datos_pareados)}\")\n",
    "                    print(f\"    Media Congruente = {datos_pareados['CO_Congruente'].mean():.4f}\")\n",
    "                    print(f\"    Media Incongruente = {datos_pareados['CO_Incongruente'].mean():.4f}\")\n",
    "                    print(f\"    p-valor = {p_valor:.6f}\")\n",
    "                    print(f\"    Sig: {sig} {'✅' if sig != 'ns' else '❌'}\")\n",
    "                    \n",
    "                    resultados_por_categoria.append({\n",
    "                        'Dataset': nombre_df,\n",
    "                        'Categoria': categoria,\n",
    "                        'Etiqueta': Etiquetas_Categorias[categoria],\n",
    "                        'Tipo': 'CO',\n",
    "                        'n': len(datos_pareados),\n",
    "                        'Media_Congruente': datos_pareados['CO_Congruente'].mean(),\n",
    "                        'Media_Incongruente': datos_pareados['CO_Incongruente'].mean(),\n",
    "                        'p_valor': p_valor,\n",
    "                        'Sig': sig\n",
    "                    })\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"\\n  CO: Error - {e}\")\n",
    "            else:\n",
    "                print(f\"\\n  CO: Datos insuficientes (n={len(datos_pareados)})\")\n",
    "        \n",
    "        # Test para CT\n",
    "        if 'CT_Congruente' in df_cat.columns and 'CT_Incongruente' in df_cat.columns:\n",
    "            datos_pareados = df_cat[['CT_Congruente', 'CT_Incongruente']].dropna()\n",
    "            \n",
    "            if len(datos_pareados) > 1:\n",
    "                try:\n",
    "                    stat, p_valor = wilcoxon(datos_pareados['CT_Congruente'], \n",
    "                                            datos_pareados['CT_Incongruente'])\n",
    "                    \n",
    "                    if p_valor < 0.001:\n",
    "                        sig = '***'\n",
    "                    elif p_valor < 0.01:\n",
    "                        sig = '**'\n",
    "                    elif p_valor < 0.05:\n",
    "                        sig = '*'\n",
    "                    else:\n",
    "                        sig = 'ns'\n",
    "                    \n",
    "                    print(f\"\\n  CT:\")\n",
    "                    print(f\"    n = {len(datos_pareados)}\")\n",
    "                    print(f\"    Media Congruente = {datos_pareados['CT_Congruente'].mean():.4f}\")\n",
    "                    print(f\"    Media Incongruente = {datos_pareados['CT_Incongruente'].mean():.4f}\")\n",
    "                    print(f\"    p-valor = {p_valor:.6f}\")\n",
    "                    print(f\"    Sig: {sig} {'✅' if sig != 'ns' else '❌'}\")\n",
    "                    \n",
    "                    resultados_por_categoria.append({\n",
    "                        'Dataset': nombre_df,\n",
    "                        'Categoria': categoria,\n",
    "                        'Etiqueta': Etiquetas_Categorias[categoria],\n",
    "                        'Tipo': 'CT',\n",
    "                        'n': len(datos_pareados),\n",
    "                        'Media_Congruente': datos_pareados['CT_Congruente'].mean(),\n",
    "                        'Media_Incongruente': datos_pareados['CT_Incongruente'].mean(),\n",
    "                        'p_valor': p_valor,\n",
    "                        'Sig': sig\n",
    "                    })\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"\\n  CT: Error - {e}\")\n",
    "            else:\n",
    "                print(f\"\\n  CT: Datos insuficientes (n={len(datos_pareados)})\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "\n",
    "# Crear DataFrame con resultados por categoría\n",
    "df_resultados_categoria = pd.DataFrame(resultados_por_categoria)\n",
    "print(\"\\n📋 Resumen de Resultados por Categoría:\\n\")\n",
    "if len(df_resultados_categoria) > 0:\n",
    "    print(df_resultados_categoria[['Dataset', 'Etiqueta', 'Tipo', 'n', 'Media_Congruente', \n",
    "                                   'Media_Incongruente', 'p_valor', 'Sig']].to_string(index=False))\n",
    "else:\n",
    "    print(\"  No hay resultados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Resumen de Resultados Significativos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"RESUMEN DE RESULTADOS SIGNIFICATIVOS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n📊 Análisis General (Todas las Poblaciones):\")\n",
    "print(\"-\"*70)\n",
    "if len(df_resultados_general) > 0:\n",
    "    sig_general = df_resultados_general[df_resultados_general['Sig'] != 'ns']\n",
    "    print(f\"\\nTotal de comparaciones: {len(df_resultados_general)}\")\n",
    "    print(f\"Comparaciones significativas: {len(sig_general)}\")\n",
    "    if len(sig_general) > 0:\n",
    "        print(\"\\nResultados significativos:\")\n",
    "        for idx, row in sig_general.iterrows():\n",
    "            print(f\"  ✅ {row['Dataset']} - {row['Tipo']}: p={row['p_valor']:.6f} ({row['Sig']})\")\n",
    "    else:\n",
    "        print(\"\\n  ❌ No hay comparaciones significativas\")\n",
    "else:\n",
    "    print(\"  No hay resultados\")\n",
    "\n",
    "print(\"\\n📊 Análisis por Categoría:\")\n",
    "print(\"-\"*70)\n",
    "if len(df_resultados_categoria) > 0:\n",
    "    sig_categoria = df_resultados_categoria[df_resultados_categoria['Sig'] != 'ns']\n",
    "    print(f\"\\nTotal de comparaciones: {len(df_resultados_categoria)}\")\n",
    "    print(f\"Comparaciones significativas: {len(sig_categoria)}\")\n",
    "    \n",
    "    if len(sig_categoria) > 0:\n",
    "        print(\"\\nResultados significativos por Dataset:\")\n",
    "        for dataset in df_resultados_categoria['Dataset'].unique():\n",
    "            print(f\"\\n  {dataset}:\")\n",
    "            sig_dataset = sig_categoria[sig_categoria['Dataset'] == dataset]\n",
    "            if len(sig_dataset) > 0:\n",
    "                for idx, row in sig_dataset.iterrows():\n",
    "                    print(f\"    ✅ {row['Etiqueta']} - {row['Tipo']}: p={row['p_valor']:.6f} ({row['Sig']})\")\n",
    "            else:\n",
    "                print(f\"    ❌ Sin resultados significativos\")\n",
    "    else:\n",
    "        print(\"\\n  ❌ No hay comparaciones significativas por categoría\")\n",
    "else:\n",
    "    print(\"  No hay resultados\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Guardar Resultados en Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar en la carpeta de procesados\n",
    "Carpeta_Salida = os.path.join(os.getcwd(), '..', 'Data', 'Procesados')\n",
    "if not os.path.exists(Carpeta_Salida):\n",
    "    os.makedirs(Carpeta_Salida)\n",
    "\n",
    "# Guardar bases actualizadas con las nuevas variables\n",
    "for nombre_df, df in dfs_Finales.items():\n",
    "    archivo = f'{nombre_df}_con_Congruencia.xlsx'\n",
    "    ruta = os.path.join(Carpeta_Salida, archivo)\n",
    "    df.to_excel(ruta, index=False)\n",
    "    print(f\"✓ {archivo} guardado\")\n",
    "\n",
    "# Guardar resultados\n",
    "if len(df_resultados_general) > 0:\n",
    "    ruta_resultados_general = os.path.join(Carpeta_Salida, 'Resultados_Congruencia_General.xlsx')\n",
    "    df_resultados_general.to_excel(ruta_resultados_general, index=False)\n",
    "    print(f\"\\n✓ Resultados generales guardados en: {ruta_resultados_general}\")\n",
    "\n",
    "if len(df_resultados_categoria) > 0:\n",
    "    ruta_resultados_categoria = os.path.join(Carpeta_Salida, 'Resultados_Congruencia_Por_Categoria.xlsx')\n",
    "    df_resultados_categoria.to_excel(ruta_resultados_categoria, index=False)\n",
    "    print(f\"✓ Resultados por categoría guardados en: {ruta_resultados_categoria}\")\n",
    "\n",
    "print(\"\\n✅ Todos los archivos guardados exitosamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Resumen Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"RESUMEN FINAL: ANÁLISIS DE CONGRUENCIA IDEOLÓGICA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n📊 Variables creadas:\")\n",
    "print(\"  - CO_Congruente (Progresistas_Izq + Conservadores_Der)\")\n",
    "print(\"  - CO_Incongruente (Progresistas_Der + Conservadores_Izq)\")\n",
    "print(\"  - CT_Congruente (Progresistas_Izq + Conservadores_Der)\")\n",
    "print(\"  - CT_Incongruente (Progresistas_Der + Conservadores_Izq)\")\n",
    "\n",
    "print(\"\\n📈 Análisis realizados:\")\n",
    "print(\"  1. Estadísticas descriptivas (todas las poblaciones)\")\n",
    "print(\"  2. Test de Wilcoxon pareado (todas las poblaciones)\")\n",
    "print(\"  3. Test de Wilcoxon pareado por categoría\")\n",
    "print(\"  4. Para Generales y Ballotage\")\n",
    "\n",
    "print(\"\\n📁 Archivos generados:\")\n",
    "print(\"  - Generales_con_Congruencia.xlsx\")\n",
    "print(\"  - Ballotage_con_Congruencia.xlsx\")\n",
    "print(\"  - Resultados_Congruencia_General.xlsx\")\n",
    "print(\"  - Resultados_Congruencia_Por_Categoria.xlsx\")\n",
    "\n",
    "print(\"\\n🎯 Interpretación:\")\n",
    "print(\"  - Congruente > Incongruente: Más cambios ideológicamente consistentes\")\n",
    "print(\"  - Congruente < Incongruente: Más cambios ideológicamente inconsistentes\")\n",
    "print(\"  - p < 0.05: La diferencia es estadísticamente significativa\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"✅ ANÁLISIS COMPLETADO\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
